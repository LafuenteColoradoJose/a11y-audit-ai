{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Entrenar Modelo de Accesibilidad (CodeT5) en Google Colab\n",
                "\n",
                "Este cuaderno te permite entrenar tu modelo de IA sin usar los recursos de tu PC local. \n",
                "Utilizará las GPUs gratuitas de Google (Tesla T4 o similar).\n",
                "\n",
                "### Pasos:\n",
                "1. Sube tu archivo `mi_dataset_wcag_gen.csv` a los archivos de este entorno (Icono de carpeta a la izquierda -> Subir).\n",
                "2. Ejecuta todas las celdas en orden (Menú 'Entorno de ejecución' -> 'Ejecutar todas').\n",
                "3. Al finalizar, se descargará automáticamente un archivo `modelo_entrenado.zip`.\n",
                "4. Descomprime ese archivo en tu carpeta `python-agent/` reemplazando la carpeta existente `mi_modelo_wcag_generativo`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Instalar dependencias necesarias\n",
                "!pip install transformers datasets accelerate torch pandas scikit-learn"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Script de Entrenamiento (Copiado de tu proyecto local)\n",
                "import pandas as pd\n",
                "from datasets import Dataset\n",
                "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
                "import torch\n",
                "import os\n",
                "\n",
                "# Desactivar WandB (Weights & Biases) para que no pida login\n",
                "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
                "\n",
                "# Verificar si el CSV existe\n",
                "if not os.path.exists('mi_dataset_wcag_gen.csv'):\n",
                "    raise FileNotFoundError(\"¡ERROR! No has subido el archivo 'mi_dataset_wcag_gen.csv'. Súbelo usando el panel de la izquierda.\")\n",
                "\n",
                "print(\"Cargando dataset...\")\n",
                "df = pd.read_csv(\"mi_dataset_wcag_gen.csv\")\n",
                "dataset = Dataset.from_pandas(df)\n",
                "\n",
                "# Dividir train/test\n",
                "dataset = dataset.train_test_split(test_size=0.1)\n",
                "\n",
                "print(\"Descargando modelo base (Salesforce/codet5-small)...\")\n",
                "checkpoint = \"Salesforce/codet5-small\"\n",
                "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
                "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
                "\n",
                "def preprocess_function(examples):\n",
                "    inputs = [\"fix wcag: \" + code for code in examples[\"input_text\"]]\n",
                "    model_inputs = tokenizer(inputs, max_length=256, truncation=True)\n",
                "    labels = tokenizer(examples[\"target_text\"], max_length=256, truncation=True)\n",
                "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
                "    return model_inputs\n",
                "\n",
                "print(\"Procesando datos...\")\n",
                "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
                "\n",
                "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
                "\n",
                "training_args = Seq2SeqTrainingArguments(\n",
                "    output_dir=\"./resultados_colab\",\n",
                "    eval_strategy=\"epoch\",\n",
                "    learning_rate=2e-5,\n",
                "    per_device_train_batch_size=8,  # Colab T4 aguanta batch 8 o 16\n",
                "    per_device_eval_batch_size=8,\n",
                "    weight_decay=0.01,\n",
                "    save_total_limit=2,\n",
                "    num_train_epochs=15,            # Mantenemos 15 épocas\n",
                "    predict_with_generate=True,\n",
                "    fp16=torch.cuda.is_available(), # Usar GPU acelerada si está disponible\n",
                "    logging_steps=50,\n",
                "    report_to='none', # Aseguramos que no intente reportar a WandB\n",
                ")\n",
                "\n",
                "trainer = Seq2SeqTrainer(\n",
                "    model=model,\n",
                "    args=training_args,\n",
                "    train_dataset=tokenized_datasets[\"train\"],\n",
                "    eval_dataset=tokenized_datasets[\"test\"],\n",
                "    tokenizer=tokenizer,\n",
                "    data_collator=data_collator,\n",
                ")\n",
                "\n",
                "print(\"¡Iniciando entrenamiento en la nube!...\")\n",
                "trainer.train()\n",
                "\n",
                "print(\"Guardando modelo...\")\n",
                "model.save_pretrained(\"./mi_modelo_wcag_generativo\")\n",
                "tokenizer.save_pretrained(\"./mi_modelo_wcag_generativo\")\n",
                "print(\"¡Modelo guardado correctamente!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Comprimir y Descargar\n",
                "!zip -r modelo_entrenado.zip mi_modelo_wcag_generativo\n",
                "\n",
                "from google.colab import files\n",
                "files.download('modelo_entrenado.zip')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}